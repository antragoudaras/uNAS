{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 23:58:22.750180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-29 23:58:22.750254: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/oper_utils.py:30: UserWarning: cannot import name 'direct' from 'dragonfly.utils.direct_fortran' (/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/direct_fortran/__init__.py)\n",
      "Could not import Fortran direct library. Dragonfly can still be used, but might be slightly slower. To get rid of this warning, install a numpy compatible Fortran compiler (e.g. gfortran) and the python-dev package and reinstall Dragonfly.\n",
      "  warn('%s\\n%s'%(e, fortran_err_msg))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/uNAS_egg_dataset_cropped_subject_id3_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.0\n",
      "Minimum test error:  0.1631944179534912\n",
      "Val errors:  [0.         0.         0.         ... 0.74137932 0.74137932 0.74137932]\n",
      "Test errors:  [0.16319442 0.16666669 0.16840279 ... 0.75       0.75       0.7517361 ]\n",
      "Minimum test error found: 0.1631944179534912 in round: 1980\n",
      "resource_features: [92528, 67502, 13246965], test_error: 0.1631944179534912\n",
      "Maximum Peak Mem Usage: [   5727   11784   12168 ... 5082000 5100208 5214000]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/rerun_uNAS_egg_dataset_cropped_subject_id3_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.0\n",
      "Minimum test error:  0.11631941795349121\n",
      "Val errors:  [0.         0.         0.         ... 0.74137932 0.74137932 0.75862069]\n",
      "Test errors:  [0.11631942 0.12847221 0.13194442 ... 0.75868055 0.7673611  0.77256945]\n",
      "Minimum test error found: 0.11631941795349121 in round: 1831\n",
      "resource_features: [344834, 107796, 45588928], test_error: 0.11631941795349121\n",
      "Maximum Peak Mem Usage: [   5365    5727    6240 ... 4626112 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('uNAS-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0a7741d7e029aabb38fa8d45f418a3fef337e7a049c994809bb975458eb7dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 00:16:48.175815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-05 00:16:48.175848: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/oper_utils.py:30: UserWarning: cannot import name 'direct' from 'dragonfly.utils.direct_fortran' (/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/direct_fortran/__init__.py)\n",
      "Could not import Fortran direct library. Dragonfly can still be used, but might be slightly slower. To get rid of this warning, install a numpy compatible Fortran compiler (e.g. gfortran) and the python-dev package and reinstall Dragonfly.\n",
      "  warn('%s\\n%s'%(e, fortran_err_msg))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/uNAS_egg_dataset_cropped_subject_id6_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.32758623361587524\n",
      "Minimum test error:  0.6475694477558136\n",
      "Val errors:  [0.32758623 0.34482759 0.36206895 ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.64756945 0.6545139  0.65625    ... 0.78819445 0.79166667 0.79166667]\n",
      "Minimum test error found: 0.6475694477558136 in round: 21\n",
      "resource_features: [757458, 676119, 108450834], test_error: 0.6475694477558136\n",
      "Maximum Peak Mem Usage: [   5158    5365    5365 ... 4883080 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/rerun_uNAS_egg_dataset_cropped_subject_id6_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.20689654350280762\n",
      "Minimum test error:  0.6128472089767456\n",
      "Val errors:  [0.20689654 0.24137932 0.24137932 ... 0.74137932 0.74137932 0.75862069]\n",
      "Test errors:  [0.61284721 0.61631945 0.61805555 ... 0.7795139  0.7795139  0.78125   ]\n",
      "Minimum test error found: 0.6128472089767456 in round: 940\n",
      "resource_features: [269169, 215868, 40930164], test_error: 0.6128472089767456\n",
      "Maximum Peak Mem Usage: [   5145    5365    5365 ... 5126000 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_high_freq_all/uNAS_egg_dataset_cropped_subject_id6_no_pruning_new_setup_128kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.017241358757019043\n",
      "Minimum test error:  0.5381944477558136\n",
      "Val errors:  [0.01724136 0.03448278 0.03448278 ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.53819445 0.55034721 0.55034721 ... 0.78645833 0.78819445 0.79166667]\n",
      "Minimum test error found: 0.5381944477558136 in round: 2411\n",
      "resource_features: [402732, 283527, 34670424], test_error: 0.5381944477558136\n",
      "Maximum Peak Mem Usage: [   4226    4497    4501 ... 4935056 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_high_freq_all/rerun2_uNAS_egg_dataset_cropped_subject_id6_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.017241358757019043\n",
      "Minimum test error:  0.5920138955116272\n",
      "Val errors:  [0.01724136 0.01724136 0.01724136 ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.5920139  0.60590279 0.6076389  ... 0.77256945 0.77777778 0.78993055]\n",
      "Minimum test error found: 0.5920138955116272 in round: 3308\n",
      "resource_features: [130440, 136677, 65070537], test_error: 0.5920138955116272\n",
      "Maximum Peak Mem Usage: [   5365    5365    5365 ... 4626112 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('uNAS-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0a7741d7e029aabb38fa8d45f418a3fef337e7a049c994809bb975458eb7dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

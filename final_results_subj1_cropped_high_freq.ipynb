{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 14:19:30.344615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-04 14:19:30.344645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/oper_utils.py:30: UserWarning: cannot import name 'direct' from 'dragonfly.utils.direct_fortran' (/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/direct_fortran/__init__.py)\n",
      "Could not import Fortran direct library. Dragonfly can still be used, but might be slightly slower. To get rid of this warning, install a numpy compatible Fortran compiler (e.g. gfortran) and the python-dev package and reinstall Dragonfly.\n",
      "  warn('%s\\n%s'%(e, fortran_err_msg))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_subj1/uNAS_egg_dataset_cropped_subject_id1_no_pruning_new_setup_64kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.051724135875701904\n",
      "Minimum test error:  0.265625\n",
      "Val errors:  [0.05172414 0.05172414 0.08620691 ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.265625   0.27430558 0.27604169 ... 0.77430555 0.7829861  0.7986111 ]\n",
      "Minimum test error found: 0.265625 in round: 3758\n",
      "resource_features: [13284, 38917, 936180], test_error: 0.265625\n",
      "Maximum Peak Mem Usage: [   4720    4720    4720 ... 4857566 5082000 5100208]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_blocks': [{'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 7, '2x_stride': True, 'has_bn': True, 'has_relu': False, 'has_prepool': False, '_weights': ['depthwise_conv2d_4548/depthwise_kernel:0', 'depthwise_conv2d_4548/bias:0']}, {'type': 'Conv2D', 'ker_size': 7, 'filters': 36, '2x_stride': True, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_4790/kernel:0', 'conv2d_4790/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 7, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['depthwise_conv2d_4549/depthwise_kernel:0', 'depthwise_conv2d_4549/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 7, '2x_stride': True, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_4550/depthwise_kernel:0', 'depthwise_conv2d_4550/bias:0']}]}, {'is_branch': True, 'layers': [{'type': '1x1Conv2D', 'filters': 36, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['conv2d_4791/kernel:0', 'conv2d_4791/bias:0']}]}, {'is_branch': True, 'layers': [{'type': '1x1Conv2D', 'filters': 36, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_4792/kernel:0', 'conv2d_4792/bias:0']}]}], 'pooling': {'type': 'avg', 'pool_size': 6}, 'dense_blocks': [{'units': 155, 'activation': 'relu', '_weights': ['dense_2326/kernel:0', 'dense_2326/bias:0']}], '_final_dense': {'units': 4, 'activation': None, '_weights': ['dense_2327/kernel:0', 'dense_2327/bias:0']}}\n"
     ]
    }
   ],
   "source": [
    "print(objects[0][3758].point.arch.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_subj1/uNAS_egg_dataset_cropped_subject_id1_no_pruning_new_setup_64kb_130_epochs_20_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.02586209774017334\n",
      "Minimum test error:  0.328125\n",
      "Val errors:  [0.0258621  0.0258621  0.04310346 ... 0.75       0.75862069 0.76724137]\n",
      "Test errors:  [0.328125   0.33680558 0.33854169 ... 0.7829861  0.78645833 0.796875  ]\n",
      "Minimum test error found: 0.328125 in round: 933\n",
      "resource_features: [346452, 133386, 46794240], test_error: 0.328125\n",
      "Maximum Peak Mem Usage: [   5727    5727    5727 ... 4857566 5082000 5100208]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_blocks': [{'is_branch': False, 'layers': [{'type': 'Conv2D', 'ker_size': 5, 'filters': 73, '2x_stride': True, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6959/kernel:0', 'conv2d_6959/bias:0']}, {'type': 'Conv2D', 'ker_size': 5, 'filters': 26, '2x_stride': True, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6960/kernel:0', 'conv2d_6960/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 5, '2x_stride': False, 'has_bn': False, 'has_relu': False, 'has_prepool': False, '_weights': ['depthwise_conv2d_3842/depthwise_kernel:0', 'depthwise_conv2d_3842/bias:0']}]}, {'is_branch': False, 'layers': [{'type': '1x1Conv2D', 'filters': 77, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6961/kernel:0', 'conv2d_6961/bias:0']}, {'type': 'Conv2D', 'ker_size': 3, 'filters': 96, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6962/kernel:0', 'conv2d_6962/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 3, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['depthwise_conv2d_3843/depthwise_kernel:0', 'depthwise_conv2d_3843/bias:0']}, {'type': 'DWConv2D', 'ker_size': 5, '2x_stride': False, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_3844/depthwise_kernel:0', 'depthwise_conv2d_3844/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'Conv2D', 'ker_size': 3, 'filters': 79, '2x_stride': False, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6963/kernel:0', 'conv2d_6963/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'DWConv2D', 'ker_size': 5, '2x_stride': True, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['depthwise_conv2d_3845/depthwise_kernel:0', 'depthwise_conv2d_3845/bias:0']}, {'type': 'Conv2D', 'ker_size': 5, 'filters': 7, '2x_stride': True, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6964/kernel:0', 'conv2d_6964/bias:0']}, {'type': '1x1Conv2D', 'filters': 79, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_6965/kernel:0', 'conv2d_6965/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'DWConv2D', 'ker_size': 3, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['depthwise_conv2d_3846/depthwise_kernel:0', 'depthwise_conv2d_3846/bias:0']}]}, {'is_branch': True, 'layers': [{'type': '1x1Conv2D', 'filters': 79, 'has_bn': True, 'has_relu': True, 'has_prepool': True, '_weights': ['conv2d_6967/kernel:0', 'conv2d_6967/bias:0']}]}], 'pooling': {'type': 'avg', 'pool_size': 4}, 'dense_blocks': [{'units': 153, 'activation': 'relu', '_weights': ['dense_2004/kernel:0', 'dense_2004/bias:0']}], '_final_dense': {'units': 4, 'activation': None, '_weights': ['dense_2005/kernel:0', 'dense_2005/bias:0']}}\n"
     ]
    }
   ],
   "source": [
    "print(objects[0][933].point.arch.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_subj1/uNAS_egg_dataset_cropped_subject_id1_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.0\n",
      "Minimum test error:  0.1822916865348816\n",
      "Val errors:  [0.         0.         0.         ... 0.74137932 0.74137932 0.75862069]\n",
      "Test errors:  [0.18229169 0.19097221 0.19444442 ... 0.75520833 0.76215278 0.7673611 ]\n",
      "Minimum test error found: 0.1822916865348816 in round: 3140\n",
      "resource_features: [131692, 134163, 24399826], test_error: 0.1822916865348816\n",
      "Maximum Peak Mem Usage: [   4972    4972    5727 ... 4857566 5082000 5100208]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_blocks': [{'is_branch': False, 'layers': [{'type': 'Conv2D', 'ker_size': 7, 'filters': 3, '2x_stride': False, 'has_bn': False, 'has_relu': False, 'has_prepool': False, '_weights': ['conv2d_9502/kernel:0', 'conv2d_9502/bias:0']}, {'type': 'Conv2D', 'ker_size': 7, 'filters': 34, '2x_stride': True, 'has_bn': True, 'has_relu': False, 'has_prepool': False, '_weights': ['conv2d_9503/kernel:0', 'conv2d_9503/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'Conv2D', 'ker_size': 7, 'filters': 23, '2x_stride': False, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_9504/kernel:0', 'conv2d_9504/bias:0']}, {'type': 'DWConv2D', 'ker_size': 3, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['depthwise_conv2d_7006/depthwise_kernel:0', 'depthwise_conv2d_7006/bias:0']}, {'type': 'DWConv2D', 'ker_size': 7, '2x_stride': False, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_7007/depthwise_kernel:0', 'depthwise_conv2d_7007/bias:0']}]}], 'pooling': {'type': 'avg', 'pool_size': 6}, 'dense_blocks': [{'units': 224, 'activation': 'relu', '_weights': ['dense_7034/kernel:0', 'dense_7034/bias:0']}], '_final_dense': {'units': 4, 'activation': None, '_weights': ['dense_7035/kernel:0', 'dense_7035/bias:0']}}\n"
     ]
    }
   ],
   "source": [
    "print(objects[0][3140].point.arch.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_subj1/uNAS_egg_dataset_cropped_subject_id1_no_pruning_new_setup_256kb_130_epochs_20_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.008620679378509521\n",
      "Minimum test error:  0.25\n",
      "Val errors:  [0.00862068 0.01724136 0.01724136 ... 0.75       0.75       0.75      ]\n",
      "Test errors:  [0.25       0.25868058 0.265625   ... 0.75694445 0.7673611  0.77430555]\n",
      "Minimum test error found: 0.25 in round: 2643\n",
      "resource_features: [114576, 99099, 17994298], test_error: 0.25\n",
      "Maximum Peak Mem Usage: [   4972    4972    4972 ... 4857566 5082000 5100208]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_blocks': [{'is_branch': False, 'layers': [{'type': 'Conv2D', 'ker_size': 7, 'filters': 10, '2x_stride': True, 'has_bn': True, 'has_relu': False, 'has_prepool': False, '_weights': ['conv2d_11615/kernel:0', 'conv2d_11615/bias:0']}, {'type': 'Conv2D', 'ker_size': 7, 'filters': 32, '2x_stride': False, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_11616/kernel:0', 'conv2d_11616/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'DWConv2D', 'ker_size': 7, '2x_stride': True, 'has_bn': True, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_9530/depthwise_kernel:0', 'depthwise_conv2d_9530/bias:0']}, {'type': 'Conv2D', 'ker_size': 3, 'filters': 32, '2x_stride': True, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['conv2d_11617/kernel:0', 'conv2d_11617/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'DWConv2D', 'ker_size': 5, '2x_stride': False, 'has_bn': True, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_9531/depthwise_kernel:0', 'depthwise_conv2d_9531/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'DWConv2D', 'ker_size': 5, '2x_stride': True, 'has_bn': True, 'has_relu': False, 'has_prepool': False, '_weights': ['depthwise_conv2d_9532/depthwise_kernel:0', 'depthwise_conv2d_9532/bias:0']}, {'type': 'DWConv2D', 'ker_size': 7, '2x_stride': True, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['depthwise_conv2d_9533/depthwise_kernel:0', 'depthwise_conv2d_9533/bias:0']}]}], 'pooling': {'type': 'avg', 'pool_size': 6}, 'dense_blocks': [{'units': 231, 'activation': 'relu', '_weights': ['dense_5961/kernel:0', 'dense_5961/bias:0']}], '_final_dense': {'units': 4, 'activation': None, '_weights': ['dense_5962/kernel:0', 'dense_5962/bias:0']}}\n"
     ]
    }
   ],
   "source": [
    "print(objects[0][2643].point.arch.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_subj1/uNAS_egg_dataset_cropped_subject_id1_new_setup_256kb_130_epochs_10_percent_pru_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.0\n",
      "Minimum test error:  0.2100694179534912\n",
      "Val errors:  [0.         0.         0.         ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.21006942 0.21354169 0.2170139  ... 0.75       0.75       0.76041667]\n",
      "Minimum test error found: 0.2100694179534912 in round: 2178\n",
      "resource_features: [8972, 3586, 422703], test_error: 0.2100694179534912\n",
      "Maximum Peak Mem Usage: [   4857    5727    5727 ... 4321880 4909320 4994000]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_blocks': [{'is_branch': False, 'layers': [{'type': 'Conv2D', 'ker_size': 5, 'filters': 76, '2x_stride': False, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['conv2d_3626/kernel:0', 'conv2d_3626/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'Conv2D', 'ker_size': 5, 'filters': 1, '2x_stride': True, 'has_bn': False, 'has_relu': False, 'has_prepool': False, '_weights': ['conv2d_3627/kernel:0', 'conv2d_3627/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 5, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': False, '_weights': ['depthwise_conv2d_3347/depthwise_kernel:0', 'depthwise_conv2d_3347/bias:0']}, {'type': 'Conv2D', 'ker_size': 7, 'filters': 56, '2x_stride': False, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_3628/kernel:0', 'conv2d_3628/bias:0']}]}, {'is_branch': True, 'layers': [{'type': 'Conv2D', 'ker_size': 3, 'filters': 9, '2x_stride': True, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['conv2d_3629/kernel:0', 'conv2d_3629/bias:0']}]}, {'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 7, '2x_stride': False, 'has_bn': False, 'has_relu': True, 'has_prepool': True, '_weights': ['depthwise_conv2d_3348/depthwise_kernel:0', 'depthwise_conv2d_3348/bias:0']}, {'type': 'DWConv2D', 'ker_size': 7, '2x_stride': False, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_3349/depthwise_kernel:0', 'depthwise_conv2d_3349/bias:0']}]}], 'pooling': {'type': 'avg', 'pool_size': 6}, 'dense_blocks': [{'units': 151, 'activation': 'relu', '_weights': ['dense_1753/kernel:0', 'dense_1753/bias:0']}], '_final_dense': {'units': 4, 'activation': None, '_weights': ['dense_1754/kernel:0', 'dense_1754/bias:0']}}\n"
     ]
    }
   ],
   "source": [
    "print(objects[0][2178].point.arch.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/rerun_uNAS_egg_dataset_cropped_subject_id1_no_pruning_new_setup_2_5kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.017241358757019043\n",
      "Minimum test error:  0.3315972089767456\n",
      "Val errors:  [0.01724136 0.01724136 0.01724136 ... 0.79310344 0.79310344 0.8275862 ]\n",
      "Test errors:  [0.33159721 0.33680558 0.3420139  ... 0.78645833 0.78993055 0.7951389 ]\n",
      "Minimum test error found: 0.3315972089767456 in round: 3882\n",
      "resource_features: [1477320, 404913, 1679794600], test_error: 0.3315972089767456\n",
      "Maximum Peak Mem Usage: [   3998    3998    4000 ... 4626112 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_blocks': [{'is_branch': False, 'layers': [{'type': 'DWConv2D', 'ker_size': 5, '2x_stride': True, 'has_bn': False, 'has_relu': False, 'has_prepool': False, '_weights': ['depthwise_conv2d_1546/depthwise_kernel:0', 'depthwise_conv2d_1546/bias:0']}, {'type': 'DWConv2D', 'ker_size': 5, '2x_stride': True, 'has_bn': True, 'has_relu': True, 'has_prepool': False, '_weights': ['depthwise_conv2d_1547/depthwise_kernel:0', 'depthwise_conv2d_1547/bias:0']}, {'type': 'DWConv2D', 'ker_size': 7, '2x_stride': True, 'has_bn': False, 'has_relu': False, 'has_prepool': True, '_weights': ['depthwise_conv2d_1548/depthwise_kernel:0', 'depthwise_conv2d_1548/bias:0']}]}], 'pooling': {'type': 'avg', 'pool_size': 6}, 'dense_blocks': [{'units': 84, 'activation': 'relu', '_weights': ['dense_1014/kernel:0', 'dense_1014/bias:0']}], '_final_dense': {'units': 4, 'activation': None, '_weights': ['dense_1015/kernel:0', 'dense_1015/bias:0']}}\n"
     ]
    }
   ],
   "source": [
    "print(objects[0][3822].point.arch.architecture)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('uNAS-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0a7741d7e029aabb38fa8d45f418a3fef337e7a049c994809bb975458eb7dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

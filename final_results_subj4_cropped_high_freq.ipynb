{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 13:52:47.840354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-03 13:52:47.840378: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/oper_utils.py:30: UserWarning: cannot import name 'direct' from 'dragonfly.utils.direct_fortran' (/home/antragoudaras/anaconda3/envs/uNAS-env/lib/python3.7/site-packages/dragonfly/utils/direct_fortran/__init__.py)\n",
      "Could not import Fortran direct library. Dragonfly can still be used, but might be slightly slower. To get rid of this warning, install a numpy compatible Fortran compiler (e.g. gfortran) and the python-dev package and reinstall Dragonfly.\n",
      "  warn('%s\\n%s'%(e, fortran_err_msg))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/uNAS_egg_dataset_cropped_subject_id4_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.27586209774017334\n",
      "Minimum test error:  0.5225694477558136\n",
      "Val errors:  [0.2758621  0.2758621  0.2758621  ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.52256945 0.52777779 0.5295139  ... 0.77430555 0.77777778 0.80034722]\n",
      "Minimum test error found: 0.5225694477558136 in round: 2210\n",
      "resource_features: [89280, 125427, 5748651], test_error: 0.5225694477558136\n",
      "Maximum Peak Mem Usage: [   5029    5158    5158 ... 4951280 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped/rerun_uNAS_egg_dataset_cropped_subject_id4_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.0\n",
      "Minimum test error:  0.375\n",
      "Val errors:  [0.         0.         0.         ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.375      0.3923611  0.40277779 ... 0.7638889  0.765625   0.77430555]\n",
      "Minimum test error found: 0.375 in round: 3618\n",
      "resource_features: [225772, 112717, 81748085], test_error: 0.375\n",
      "Maximum Peak Mem Usage: [   4972    5365    5727 ... 4744758 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_high_freq_all/rerun2_uNAS_egg_dataset_cropped_subject_id4_no_pruning_new_setup_256kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.0\n",
      "Minimum test error:  0.5104166567325592\n",
      "Val errors:  [0.         0.         0.         ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.51041666 0.5138889  0.52604166 ... 0.7829861  0.78993055 0.8107639 ]\n",
      "Minimum test error found: 0.5104166567325592 in round: 3457\n",
      "resource_features: [110548, 200814, 40627652], test_error: 0.5104166567325592\n",
      "Maximum Peak Mem Usage: [   5365    5727    5727 ... 5046426 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "objects = []\n",
    "with (open(\"./artifacts/cnn_egg_cropped_high_freq_all/rerun_uNAS_egg_dataset_cropped_subject_id4_no_pruning_new_setup_128kb_130_epochs_10_percent_agingevosearch_state.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum val error:  0.051724135875701904\n",
      "Minimum test error:  0.5520833432674408\n",
      "Val errors:  [0.05172414 0.06896549 0.06896549 ... 0.75862069 0.75862069 0.75862069]\n",
      "Test errors:  [0.55208334 0.56770834 0.56944445 ... 0.78125    0.7829861  0.78472222]\n",
      "Minimum test error found: 0.5520833432674408 in round: 3493\n",
      "resource_features: [190632, 94748, 13190641], test_error: 0.5520833432674408\n",
      "Maximum Peak Mem Usage: [   4131    5365    5365 ... 4946360 5286960 6237064]\n"
     ]
    }
   ],
   "source": [
    "val_errors = []\n",
    "test_errors = []\n",
    "peak_mem_usage =[]\n",
    "for point in objects[0]:\n",
    "    val_errors.append(point.val_error)\n",
    "    test_errors.append(point.test_error)\n",
    "    peak_mem_usage.append(point.resource_features[0])\n",
    "    \n",
    "print(\"Minimum val error: \", min(val_errors))\n",
    "print(\"Minimum test error: \", min(test_errors))\n",
    "print(\"Val errors: \", np.sort(val_errors))\n",
    "print(\"Test errors: \", np.sort(test_errors))\n",
    "minimum_arg = np.argmin(test_errors)\n",
    "print(\"Minimum test error found: {} in round: {}\".format(test_errors[minimum_arg], minimum_arg))\n",
    "print(\"resource_features: {}, test_error: {}\".format(objects[0][minimum_arg].resource_features, objects[0][minimum_arg].test_error))\n",
    "print(\"Maximum Peak Mem Usage: {}\".format(np.sort(peak_mem_usage)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('uNAS-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0a7741d7e029aabb38fa8d45f418a3fef337e7a049c994809bb975458eb7dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
